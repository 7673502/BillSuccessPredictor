{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering the Data\n",
    "We'll be using the [congress.gov API](https://github.com/LibraryOfCongress/api.congress.gov) to request all of the data on bills introduced in the House of Representatives during the 117th Congress. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cdg_client import CDGClient\n",
    "\n",
    "with open(\"congress_api.env\", \"r\") as f:\n",
    "    api_key = f.read()\n",
    "\n",
    "client = CDGClient(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get information on HR 3684\n",
    "example_bill = client.get(\"bill/117/hr/3684\")\n",
    "print(example_bill[0].get(\"bill\").get(\"title\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "from tqdm.contrib.logging import logging_redirect_tqdm\n",
    "from requests.exceptions import HTTPError\n",
    "from tenacity import retry, wait_fixed, retry_if_exception_type, before_sleep_log\n",
    "import logging\n",
    "import sys\n",
    "import requests\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(stream=sys.stderr, level=logging.DEBUG)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# suppress debug logs from urllib3\n",
    "logging.getLogger(\"urllib3\").setLevel(logging.WARNING)\n",
    "\n",
    "# custom logging function that logs retries\n",
    "def retry_log(logger, level):\n",
    "    def wrapper(retry_state):\n",
    "        if retry_state.attempt_number > 1:\n",
    "            logger.log(level, f\"Retrying {retry_state.fn.__name__} (attempt {retry_state.attempt_number})\")\n",
    "    return wrapper\n",
    "\n",
    "@retry(wait=wait_fixed(300), retry=retry_if_exception_type(HTTPError), before_sleep=retry_log(logger, logging.DEBUG))\n",
    "def getBill(congress, chamber, number):\n",
    "    return client.get(f\"bill/{congress}/{chamber}/{number}\")\n",
    "\n",
    "@retry(wait=wait_fixed(300), retry=retry_if_exception_type(HTTPError), before_sleep=retry_log(logger, logging.DEBUG))\n",
    "def getBillText(congress, chamber, number):\n",
    "    return client.get(f\"bill/{congress}/{chamber}/{number}/text\")\n",
    "\n",
    "@retry(wait=wait_fixed(300), retry=retry_if_exception_type(HTTPError), before_sleep=retry_log(logger, logging.DEBUG))\n",
    "def getBillSummary(congress, chamber, number):\n",
    "    return client.get(f\"bill/{congress}/{chamber}/{number}/summaries\")\n",
    "\n",
    "@retry(wait=wait_fixed(300), retry=retry_if_exception_type(HTTPError), before_sleep=retry_log(logger, logging.DEBUG))\n",
    "def getBillActions(congress, chamber, number):\n",
    "    return client.get(f\"bill/{congress}/{chamber}/{number}/actions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_BILLS = 9709# 9709 bills were introduced by the House of the 117th congress\n",
    "\n",
    "start = 1\n",
    "\n",
    "with logging_redirect_tqdm():\n",
    "    for i in tqdm(range(start, NUM_BILLS + 1)):\n",
    "        bill = getBill(117, \"hr\", i)    \n",
    "\n",
    "        with open(f\"BillData/JSONFiles/{str(i).zfill(5)}.json\", \"w\") as outfile: \n",
    "            json.dump(bill[0].get(\"bill\"), outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_BILLS = 9709\n",
    "start = 1\n",
    "\n",
    "with logging_redirect_tqdm():\n",
    "    for i in tqdm(range(start, NUM_BILLS + 1)):\n",
    "        sources = getBillText(117, \"hr\", i)\n",
    "\n",
    "        try:\n",
    "            formats = sources[0].get(\"textVersions\")[0].get(\"formats\")\n",
    "        except IndexError:\n",
    "            print(f\"Failed to retrieve the content. No text is available for H.R. {i}.\")\n",
    "            continue\n",
    "\n",
    "        url = next((item[\"url\"] for item in formats if item[\"type\"] == \"Formatted Text\"), None)\n",
    "\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            with open(f\"BillData/BillText/{str(i).zfill(5)}.htm\", \"w\", encoding=\"utf-8\") as file:\n",
    "                file.write(response.text)\n",
    "        else:\n",
    "            print(f\"Failed to retrieve the content. Status code: {response.status_code}\")\n",
    "        \n",
    "        # wait before sending more https requests\n",
    "        sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_BILLS = 9709\n",
    "start = 4944\n",
    "\n",
    "with logging_redirect_tqdm():\n",
    "    for i in tqdm(range(start, NUM_BILLS + 1)):\n",
    "        response = getBillSummary(117, \"hr\", i)[0].get(\"summaries\")\n",
    "\n",
    "        if len(response) == 0:\n",
    "            logging.debug(f\"Failed to retrieve the content. No summary is available for H.R. {i}\")\n",
    "            continue\n",
    "\n",
    "        summary = response[0].get(\"text\")\n",
    "        \n",
    "        with open(f\"BillData/BillSummaries/{str(i).zfill(5)}.htm\", \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(summary)\n",
    "        \n",
    "        sleep(1.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_BILLS = 9709\n",
    "start = 246\n",
    "\n",
    "with logging_redirect_tqdm():\n",
    "    for i in tqdm(range(start, NUM_BILLS + 1)):\n",
    "        actions = getBillActions(117, \"hr\", i)    \n",
    "\n",
    "        with open(f\"BillData/BillActions/{str(i).zfill(5)}.json\", \"w\") as outfile: \n",
    "            json.dump(actions, outfile)\n",
    "        \n",
    "        sleep(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assembling the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get pretrained GloVe model - Common Crawl (42B tokens, 1.9M vocab, uncased, 300d vectors, 1.75 GB download)\n",
    "!wget https://huggingface.co/stanfordnlp/glove/resolve/main/glove.42B.300d.zip\n",
    "!tar -xf glove.42B.300d.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clean_bill_summary(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        soup = BeautifulSoup(file, 'html.parser')\n",
    "\n",
    "        # Remove <b> and <strong> tags (these tags contain the bill title)\n",
    "        for tag in ['b', 'strong']:\n",
    "            for match in soup.find_all(tag):\n",
    "                match.decompose()\n",
    "\n",
    "        # Convert to string and lowercase\n",
    "        summary = \" \".join(soup.stripped_strings)\n",
    "        summary = summary.lower()\n",
    "\n",
    "        # Drop all punctuation\n",
    "        summary = re.sub(r\"[^\\w\\s]\", \"\", summary)\n",
    "        \n",
    "    return summary\n",
    "\n",
    "def get_clean_bill_title(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "        title = data[\"title\"].lower()\n",
    "        title = re.sub(r\"[^\\w\\s]\", \"\", title)\n",
    "\n",
    "    return title\n",
    "\n",
    "def tokenize_text(text):\n",
    "    # tokenize text\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "\n",
    "    # get rid of stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    return tokens\n",
    "\n",
    "# example usage\n",
    "get_clean_bill_summary(\"BillData/BillSummaries/00033.htm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to test if a bill passed house\n",
    "def did_bill_pass(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        if \"Senate\" in file.read():\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "# example usage\n",
    "did_bill_pass(\"BillData/BillActions/07776.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing to see how many bills are missing the \"policyArea\" attribute\n",
    "\n",
    "total = 0\n",
    "count = 0\n",
    "\n",
    "for file in tqdm(Path(\"BillData/BillSummaries\").glob('*.htm')):\n",
    "    bill_number = str(file).split(\"\\\\\")[-1][:-4]\n",
    "\n",
    "    with open(f\"BillData/JSONFiles/{bill_number}.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "        try:\n",
    "            policy_area = data[\"policyArea\"][\"name\"]\n",
    "        except KeyError:\n",
    "            count += 1\n",
    "        \n",
    "        total +=1\n",
    "\n",
    "print(f\"{count}/{total}={count/total}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"bill_id\", \n",
    "            \"title\", \n",
    "            \"summary\", \n",
    "            \"sponsor_party\", \n",
    "            \"sponsor_state\",\n",
    "            \"sponsor_district\",\n",
    "            \"policy_area\", \n",
    "            \"subjects_count\", \n",
    "            \"introduced_date\",\n",
    "            \"passed_house\"]\n",
    "\n",
    "dataset = pd.DataFrame(columns = features)\n",
    "\n",
    "# iterate through htm files in the BillSummaries directory\n",
    "for file in tqdm(Path(\"BillData/BillSummaries\").glob('*.htm')):\n",
    "    bill_number = str(file).split(\"\\\\\")[-1][:-4]\n",
    "    \n",
    "    summary = get_clean_bill_summary(file)\n",
    "    summary = tokenize_text(summary)\n",
    "\n",
    "    # remove word \"bill\" if it is first word\n",
    "    if summary[0] == \"bill\":\n",
    "        summary.pop(0)\n",
    "\n",
    "    with open(f\"BillData/JSONFiles/{bill_number}.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "        \n",
    "        title = data[\"title\"].lower()\n",
    "        title = re.sub(r\"[^\\w\\s]\", \"\", title)\n",
    "        title = tokenize_text(title)\n",
    "\n",
    "        sponsor_party = data[\"sponsors\"][0][\"party\"]\n",
    "        sponsor_state = data[\"sponsors\"][0][\"state\"]\n",
    "        \n",
    "        introduced_date = data[\"introducedDate\"]\n",
    "\n",
    "\n",
    "        passed_house = did_bill_pass(f\"BillData/BillActions/{bill_number}.json\")\n",
    "\n",
    "        # 5 bills are missing subject count\n",
    "        try:\n",
    "            subjects_count = data[\"subjects\"][\"count\"]\n",
    "        except Exception:\n",
    "            subjects_count = 1\n",
    "\n",
    "        # 29 bills are missing the policyArea attribute\n",
    "        try:\n",
    "            policy_area = data[\"policyArea\"][\"name\"]\n",
    "        except KeyError:\n",
    "            policy_area = \"unknown\"\n",
    "\n",
    "        # some regions only have one district\n",
    "        # if the bill is missing a sponsor district, it's likely the bill is from such a region\n",
    "        try:\n",
    "            sponsor_district = data[\"sponsors\"][0][\"district\"]\n",
    "        except KeyError:\n",
    "            sponsor_district = 1\n",
    "        \n",
    "    \n",
    "    # add the row to the dataset\n",
    "    new_row = pd.DataFrame([[int(bill_number),\n",
    "                                 title,\n",
    "                                 summary,\n",
    "                                 sponsor_party,\n",
    "                                 sponsor_state,\n",
    "                                 sponsor_district,\n",
    "                                 policy_area,\n",
    "                                 subjects_count,\n",
    "                                 introduced_date,\n",
    "                                 passed_house]], columns = features)\n",
    "    \n",
    "    dataset = pd.concat([dataset, new_row])\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode these columns\n",
    "dataset_encoded = pd.get_dummies(dataset, columns=[\"sponsor_party\", \"sponsor_state\", \"policy_area\"])\n",
    "\n",
    "# convert dates to datetime format\n",
    "dataset_encoded[\"introduced_date\"] = pd.to_datetime(dataset_encoded[\"introduced_date\"], format=\"%Y-%m-%d\")\n",
    "\n",
    "dataset_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start and end dates of 117th congress\n",
    "congress_start_date = dataset_encoded[\"introduced_date\"].min()\n",
    "congress_end_date = dataset_encoded[\"introduced_date\"].max()\n",
    "\n",
    "print(f\"Congress Start Date: {congress_start_date}\")\n",
    "print(f\"Congress Start Date: {congress_end_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate the total number of days in the congressional session\n",
    "total_days = (congress_end_date - congress_start_date).days\n",
    "\n",
    "# function to normalize the dates between 0 and 1 where 0 is the start of congress and 1 is the end date\n",
    "def normalize_date(date, start_date, total_days):\n",
    "    return (date - start_date).days / total_days\n",
    "\n",
    "# apply the normalization function\n",
    "dataset_encoded['introduced_date'] = dataset_encoded['introduced_date'].apply(normalize_date, args=(congress_start_date, total_days))\n",
    "\n",
    "dataset_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_encoded.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_encoded.to_feather('117hrbills_encoded.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_feather(\"117hrbills_encoded.feather\")\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
